## **Explaining Medical Decisions Made by AI**
This project is a product of my participation in a 2024 summer research experience for undergraduates (REU) at the University of Minnesota. The REU's focus is human-centered computing for social good, and I am advised by Professor Qianwen Wang.
### <ins>Project description</ins>
Our research group is interested in studying how large language models (LLMs) respond differently to various medical-related inquiries. Specifically, we are studying the difference in how LLMs respond to medical inquiries formulated in a professional tone versus a demographic-specific tone. To test this, we will feed various types of medical-related questions into LLMs in three stages. 
#### _Stage 1_
The input is questions from the Medical Question Answering Dataset (MedQuAD). This dataset contains 47,457 questions obtained from 12 NIH websites. We will feed these questions into the LLMs we are testing and record the LLMs' responses. Since the input is professional medical-related questions, this stage of our research will serve as a baseline.
#### _Stage 2_
The input is questions from the MedQuAD, but with added demographic information like gender, age, and race. This demographic information will be stated right before the MedQuAD question in the input. We will feed these questions into the LLMs we are testing and record the LLMs' responses. 